---
title: Scale-Invariant Unconstrained Online Learning
abstract: 'We consider a variant of online convex optimization in which both the instances (input vectors) and the comparator (weight vector) are unconstrained. We exploit a natural scale invariance symmetry in our unconstrained setting: the predictions of the optimal comparator are invariant under any linear transformation of the instances.  Our goal is to design online algorithms which also enjoy this property, i.e. are scale-invariant. We start with the case of coordinate-wise invariance, in which the individual coordinates (features) can be arbitrarily rescaled.  We give an algorithm, which achieves essentially optimal regret bound in this setup, expressed by means of a coordinate-wise scale-invariant norm of the comparator. We then study general invariance with respect to arbitrary linear transformations.  We first give a negative result, showing that no algorithm can achieve a meaningful bound in terms of scale-invariant norm of the comparator in the worst case. Next, we compliment this result with a positive one, providing an algorithm which "almost" achieves the desired bound, incurring only a logarithmic overhead in terms of the norm of the instances.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: kotłowski17a
month: 0
tex_title: Scale-Invariant Unconstrained Online Learning
firstpage: 412
lastpage: 433
page: 412-433
order: 412
cycles: false
author:
- given: Wojciech
  family: Kotłowski
date: 2017-10-11
address: 
publisher: PMLR
container-title: Proceedings of the 28th International Conference on Algorithmic Learning
  Theory
volume: '76'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 10
  - 11
pdf: http://proceedings.mlr.press/v76/kotłowski17a/kotłowski17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
