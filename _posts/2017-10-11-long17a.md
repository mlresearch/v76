---
title: New bounds on the price of bandit feedback for mistake-bounded online multiclass learning
abstract: This paper is about two generalizations of the mistake bound model to online multiclass classification. In the {\em standard model}, the learner receives the correct classification at the end of each round, and in the {\em bandit model}, the learner only finds out whether its prediction was correct or not.  For a set $F$ of multiclass classifiers, let $\mathrm{opt}_{\mathrm{std}}(F)$ and $\mathrm{opt}_{\mathrm{bandit}}(F)$ be the optimal bounds for learning $F$ according to these two models.  We show that an $$ \mathrm{opt}_{\mathrm{bandit}}(F) \leq (1 + o(1)) (|Y| \ln |Y|) \mathrm{opt}_{\mathrm{std}}(F) $$ bound is the best possible up to the leading constant, closing a $\Theta(\log |Y|)$ factor gap.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: long17a
month: 0
tex_title: New bounds on the price of bandit feedback for mistake-bounded online multiclass
  learning
firstpage: 3
lastpage: 10
page: 3-10
order: 3
cycles: false
author:
- given: Philip M.
  family: Long
date: 2017-10-11
address: 
publisher: PMLR
container-title: Proceedings of the 28th International Conference on Algorithmic Learning
  Theory
volume: '76'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 10
  - 11
pdf: http://proceedings.mlr.press/v76/long17a/long17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
